{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## \"NL2SQLAgent\": WXAI VERSION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this version is meant to be executed in WATSONX_AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies and restart kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1811cdbc-a5e0-45c3-a40d-771c496fece1"
   },
   "outputs": [],
   "source": [
    "!pip install pydantic==2.11.1 langchain==0.3.22 langchain-core==0.3.51 langchain-ibm==0.3.10 langchain-text-splitters==0.3.8 PyHive==0.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "09399270-56dd-413c-b37d-150b4850dbf9",
    "msg_id": "92f9a770-aa7e-4524-a7d1-6ab8cf9b11f2"
   },
   "outputs": [],
   "source": [
    "# Restart kernel\n",
    "import os\n",
    "os._exit(00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "af8194ce-4a81-4bf2-9bdd-f6966dacb6a5"
   },
   "outputs": [],
   "source": [
    "#test for potential failure on this package\n",
    "from langgraph.prebuilt import create_react_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "414cd9b3-e221-4de1-834c-0deb3c88080d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from ibm_watsonx_ai import Credentials, APIClient\n",
    "from ibm_watsonx_ai.deployments import RuntimeContext\n",
    "import getpass\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3b3469c-4bf9-4be3-ace9-c356e6fcd123"
   },
   "source": [
    "## Load connections information from the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "87da4492-6d0a-4438-add2-7c7bd30a235d"
   },
   "outputs": [],
   "source": [
    "# list your connections\n",
    "display(wslib.list_connections())\n",
    "# make sure you use the right connection name for presto\n",
    "presto_conn = wslib.get_connection('presto_connection')\n",
    "cos_conn = wslib.get_connection('cos_connection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3b0cc128-30e4-4df5-8a74-929e81bc656a"
   },
   "source": [
    "### Load env.txt file with configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "af10d6b3-10dc-47b6-9ea3-db36acde0150"
   },
   "outputs": [],
   "source": [
    "with open('.env_all', 'wb') as env_file:\n",
    "    env_file.write(wslib.load_data('env.txt').read())\n",
    "# environmental variables store credentials and configuration\n",
    "load_dotenv('.env_all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abf85b27-ed38-4c64-bc6f-e56ad5d3c338"
   },
   "source": [
    "### Enter your Cloud API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "43ed28a3-8c42-4cd9-8c9e-68c4d9398325"
   },
   "outputs": [],
   "source": [
    "CLOUD_API_KEY = getpass.getpass(\"Enter your Cloud API key: \")\n",
    "print(\"Cloud API Key recieved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ae446755-996c-458e-8549-ace06b24568d"
   },
   "outputs": [],
   "source": [
    "# settings\n",
    "params = {\n",
    "        \"space_id\": os.getenv(\"WATSONX_DEPLOYMENT_SPACE_ID\"),\n",
    "        \"project_id\" : os.getenv(\"WATSONX_PROJECT_ID\"),\n",
    "        \"api_key\": CLOUD_API_KEY,\n",
    "        \"presto_host\" : presto_conn[\"engine_host\"],\n",
    "        \"presto_port\" : presto_conn[\"engine_port\"],\n",
    "        \"presto_user\" : \"ibmlhapikey\",\n",
    "        \"presto_key\" : presto_conn[\"api_key\"],\n",
    "        \"clients_schema\": os.getenv(\"SCHEMA_DATA_I\"),\n",
    "        \"service_url\" : os.getenv(\"WATSONX_URL\")\n",
    "    }\n",
    "\n",
    "\n",
    "assert params['api_key'], \"could not load environment variables properly\"\n",
    "\n",
    "display(\"Check you parameters\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d37e66a9-7d73-4df6-b33c-8d9e90e84b73"
   },
   "outputs": [],
   "source": [
    "credentials = Credentials(\n",
    "    url = params['service_url'],\n",
    "    api_key = params['api_key']    \n",
    ")\n",
    "\n",
    "space_id = params['space_id'] \n",
    "project_id = params['project_id'] \n",
    "api_client = APIClient(credentials=credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployable service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c48521da-61e5-42fc-ab16-472c4b824ee8"
   },
   "outputs": [],
   "source": [
    "def gen_ai_service(context, params = params, **custom):    \n",
    "\n",
    "    from ibm_watsonx_ai import APIClient, Credentials    \n",
    "    from langchain_ibm import WatsonxLLM    \n",
    "    from langchain_core.tools import tool        \n",
    "    from langchain.prompts import PromptTemplate\n",
    "    from langchain_core.output_parsers import JsonOutputParser    \n",
    "    from langchain_core.messages import AIMessage, HumanMessage\n",
    "    from pydantic import BaseModel, Field        \n",
    "    from langchain_ibm import ChatWatsonx\n",
    "    from pyhive import presto\n",
    "    from pyhive.exc import DatabaseError    \n",
    "    from langgraph.prebuilt import create_react_agent\n",
    "        \n",
    "    service_url = params.get(\"service_url\")\n",
    "    space_id = params.get(\"space_id\")\n",
    "    project_id = params.get(\"project_id\")\n",
    "    api_key = params.get(\"api_key\")\n",
    "    presto_host = params.get(\"presto_host\")\n",
    "    presto_port = params.get(\"presto_port\")\n",
    "    presto_user = params.get(\"presto_user\")\n",
    "    presto_key = params.get(\"presto_key\")\n",
    "    clients_schema = params.get(\"clients_schema\")\n",
    "\n",
    "    api_client = APIClient(\n",
    "        credentials=Credentials(url=service_url, token=context.generate_token()),\n",
    "        space_id= space_id\n",
    "    )\n",
    "    model_id=\"meta-llama/llama-3-3-70b-instruct\"\n",
    "    \n",
    "    api_client.set.default_space(space_id)\n",
    "\n",
    "\n",
    "    def gen_ai_service_with_langgraph():\n",
    "\n",
    "        def create_llm(max_new_tokens=1000, min_new_tokens=100, temperature=0, decoding_method='greedy', repetition_penalty=1, model_id=\"meta-llama/llama-3-3-70b-instruct\"):\n",
    "            parameters = {\n",
    "                \"decoding_method\": decoding_method,\n",
    "                \"max_new_tokens\": max_new_tokens,\n",
    "                \"min_new_tokens\": min_new_tokens,\n",
    "                \"repetition_penalty\": repetition_penalty                \n",
    "            }            \n",
    "            return WatsonxLLM(\n",
    "                model_id= model_id,\n",
    "                url=service_url,\n",
    "                apikey=api_key,\n",
    "                project_id=project_id,\n",
    "                params=parameters,\n",
    "            )\n",
    "\n",
    "        model = create_llm()\n",
    "        chat = ChatWatsonx(model_id=model_id, watsonx_client=api_client)\n",
    "        class sql_code(BaseModel):\n",
    "            \"\"\"Schema for Python solutions.\"\"\"\n",
    "            prefix: str = Field(description=\"Description of the problem and approach\")\n",
    "            code: str = Field(description=\"Code block not including import statements\")\n",
    "\n",
    "        # Tool creation.\n",
    "        @tool(parse_docstring=True)\n",
    "        def text2SQL(query: str) -> str:\n",
    "            \"\"\"\n",
    "            text2SQL tool which generates SQL code and executes it against the database for a given natural language query\\\n",
    "                about a customer's personal information such as name, address, profession, zip code as well as their accounts and stock holdings status.\n",
    "\n",
    "            Args:\n",
    "                query: The natural language query. customer_id MUST be used when searching for information related to a specific client\n",
    "\n",
    "            Returns:\n",
    "                The result from the database including the primary key used for further queries\n",
    "            \"\"\"\n",
    "\n",
    "            print(\"-------------Generating SQL-------------------\")\n",
    "            print(\"User query:\",query)            \n",
    "            max_retries = 5\n",
    "\n",
    "            def text2SQL_chain():\n",
    "                prompt = PromptTemplate(\n",
    "                    template=\"\"\"\n",
    "                    <|begin_of_text|><start_header_id|>system<|end_header_id|>\n",
    "                    You are an expert in SQL and understanding the relationship between tables. You are to generate executable SQL queries specifically for PrestoDB that answers the user's questions provided in English.\n",
    "                    The table schema metadata is also provided to assist you in generating these queries.\n",
    "                    Always use the following instructions to format your response to user queries:\\n {format_instructions}\n",
    "                    <start_header_id|>user<|end_header_id|>\n",
    "\n",
    "                    The instructions are as follows:\n",
    "                    1. Understand the user's question and pull together all relevant tables as necessary.\n",
    "                    2. Understand the schema of the tables and how they will be joined together.\n",
    "                    3. Provide the output in the json format provided with executable SQL queries to get the desired results.\n",
    "                    4. Ensure the column you are querying corresponds to the correct table and column name.\n",
    "                    5. ALWAYS return ALL the information from the customers_table in your queries to ensure follow up questions can be answered easily.\n",
    "                    6. DO NOT return any additional text other than the JSON object.\n",
    "\n",
    "                    Table Schema: \n",
    "                    There are 3 tables of interest.\n",
    "\n",
    "\n",
    "                    Table 1: postgres_catalog.bankdemo.customers_table containing the following columns: customer_id (primary key), name, address, zip_code, credit_rating, age,\\\n",
    "                        gender, marital_status, profession, nbr_years_cli, risk_score, city, state, and profile_url\n",
    "                    Table 2: iceberg_data.{clients_schema}.accounts_table containing the following columns: customer_id (foreign key), account_id (primary key)\n",
    "                    Table 3: iceberg_data.{clients_schema}.holdings_table containing the following columns: account_id (foreign key), holding_id (primary key), asset_ticker, holding_amt and tax_liability\n",
    "\n",
    "                    Example queries:1. How many rows are there in customers table.\n",
    "                            Answer: SELECT COUNT(*) as row_count FROM postgres_catalog.bankdemo.customers_table\n",
    "\n",
    "                    Question: {question}<|eot_id|>\n",
    "                    <start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "                    JSON Output:\n",
    "                    \"\"\",\n",
    "                    input_variables=[\"question\", \"format_instruction\", \"clients_schema\"]\n",
    "                )\n",
    "                t2s_chain = prompt | model\n",
    "                return t2s_chain\n",
    "            chain = text2SQL_chain()\n",
    "            parser = JsonOutputParser(pydantic_object=sql_code)\n",
    "            format_instructions = parser.get_format_instructions()\n",
    "            result = chain.invoke({\"question\": query, \"format_instructions\": format_instructions, \"clients_schema\": clients_schema})\n",
    "            print(\"-----------------------FINISHED GENERATING----------------------\")\n",
    "            count = 1\n",
    "            qry = \"\"\n",
    "            conn = presto.connect(host=presto_host, port=presto_port, username=presto_user, password=presto_key, protocol=\"https\")\n",
    "            response = \"\"\n",
    "            print(result)\n",
    "            while count <= max_retries:\n",
    "                try:\n",
    "                    parsed_result = parser.invoke(result)\n",
    "                    qry = parsed_result[\"code\"].replace(';', '')\n",
    "                    print(\"------------------QUERY SQL----------------------\")\n",
    "                    print(qry)\n",
    "                    cursor = conn.cursor()\n",
    "                    cursor.execute(qry)\n",
    "                    response = cursor.fetchall()            \n",
    "                    print(\"-------------------SQL Execution Success!---------------------\")\n",
    "                    print(\"response:\",response)\n",
    "                    break\n",
    "                except DatabaseError as e:\n",
    "                    print(f\"--------------------Error with SQL...Regenerating--------------------{count} out of 5 times\")\n",
    "                    response = \"\"\n",
    "                    cursor.close()\n",
    "                    result = chain.invoke({\"question\": f\"The original query was {query} but your last generation of {result} returned database error {e}. Please fix your response and regenerate\", \"format_instructions\": format_instructions, \"clients_schema\": clients_schema})\n",
    "                    print(f\"Error was {e}\")\n",
    "                    count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"--------------------Error with Parsing SQL...Regenerating--------------------{count} out of 5 times\")\n",
    "                    response = \"\"\n",
    "                    result = chain.invoke({\"question\": f\"The original query was {query} but your last generation of {result} returned parsing error {e}. Please fix your response and regenerate.\", \"format_instructions\": format_instructions, \"clients_schema\": clients_schema})\n",
    "                    print(f\"Error was {e}\")\n",
    "                    # print(result)\n",
    "                    count += 1\n",
    "\n",
    "            if not response:\n",
    "                print(\"Failed to generate SQL from given text or no results were returned\")\n",
    "                return \"No results found\"\n",
    "\n",
    "            return response\n",
    "        \n",
    "        tools = [text2SQL]\n",
    "\n",
    "        # system_prompt = \"\"\"You are a helpful AI assistant, please respond to the user's query to the best of your ability!\n",
    "        # Take advantage of the tools and DO NOT generate any SQL yourself. Call the tool with natural language when information from the database is needed.        \n",
    "        # When calling the SQL generation tool, use the customer_id when it is available.\n",
    "        # You MUST display all information the tool output in a table format when it makes sense.\n",
    "        # The database contains the following information and can be queried using the text2SQL tool: customer_id, name, address, zip code, profession, stocks holdings, holdings amount, city, state, and risk score.        \n",
    "        # \"\"\"\n",
    "        \n",
    "        langgraph_agent_executor = create_react_agent(chat, tools)\n",
    "                        \n",
    "        return langgraph_agent_executor\n",
    "    \n",
    "    def convert_messages(messages):\n",
    "        converted_messages = []\n",
    "        for message in messages:\n",
    "            if (message[\"role\"] == \"user\"):\n",
    "                converted_messages.append(HumanMessage(content=message[\"content\"]))\n",
    "            elif (message[\"role\"] == \"assistant\"):\n",
    "                converted_messages.append(AIMessage(content=message[\"content\"]))\n",
    "        return converted_messages\n",
    "        \n",
    "    def generate(context) -> dict:\n",
    "        \n",
    "        api_client.set_token(context.get_token())   \n",
    "        payload = context.get_json()     \n",
    "        messages = payload[\"messages\"]                \n",
    "        graph = gen_ai_service_with_langgraph()        \n",
    "        print(convert_messages(messages))\n",
    "        response = graph.invoke({\n",
    "                                    \"messages\": convert_messages(messages)\n",
    "                                 })        \n",
    "        last_message = response[\"messages\"][-1]\n",
    "        generated_response = last_message.content\n",
    "        execute_response = {\n",
    "            \"headers\": {\n",
    "                \"Content-Type\": \"application/json\"\n",
    "            },\n",
    "            \"body\": {\n",
    "                \"choices\": [{\n",
    "                    \"index\": 0,\n",
    "                    \"message\": {\n",
    "                       \"role\": \"assistant\",\n",
    "                       \"content\": generated_response\n",
    "                    }\n",
    "                }]\n",
    "            }\n",
    "        }                \n",
    "        return execute_response    \n",
    "    \n",
    "    def generate_stream(context):\n",
    "        api_client.set_token(context.get_token())\n",
    "   \n",
    "        payload = context.get_json()     \n",
    "        messages = payload[\"messages\"]                \n",
    "        graph = gen_ai_service_with_langgraph()        \n",
    "        print(convert_messages(messages))\n",
    "        response = graph.invoke({\n",
    "                                    \"messages\": convert_messages(messages)\n",
    "                                 })        \n",
    "        last_message = response[\"messages\"][-1]\n",
    "        generated_response = last_message.content        \n",
    "        for chunk in generated_response:\n",
    "            chunk_response = {\n",
    "                \"choices\": [{\n",
    "                    \"index\": 0,\n",
    "                    \"delta\": {\n",
    "                        \"role\": \"assistant\",\n",
    "                        \"content\": chunk\n",
    "                    }\n",
    "                    \n",
    "                }]\n",
    "            }\n",
    "            yield chunk_response\n",
    "                    \n",
    "    return generate, generate_stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "52ca928e-fe2d-4da5-9576-5b5f6f78d76f"
   },
   "outputs": [],
   "source": [
    "context = RuntimeContext(api_client=api_client)\n",
    "\n",
    "streaming = True\n",
    "findex = 1 if streaming else 0\n",
    "\n",
    "local_function = gen_ai_service(context, space_id=space_id)[findex]\n",
    "\n",
    "question= \"Who are the clients (including names and IDs) who invested in IBM and is holding more than 10000. Give me just 5 such clients\"        \n",
    "# question = \"How many rows are there in customers_table \"\n",
    "\n",
    "messages =[{ \"role\" : \"user\", \"content\": question }]\n",
    "\n",
    "context.request_payload_json = {\"messages\":messages}\n",
    "\n",
    "response = local_function(context)\n",
    "\n",
    "if (streaming):\n",
    "    print(response)\n",
    "    for chunk in response:\n",
    "        print(chunk[\"choices\"][0][\"delta\"][\"content\"], end=\"\", flush=True)\n",
    "else:\n",
    "    print(response)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cd532006-662e-4537-91d3-c14508375dbc"
   },
   "outputs": [],
   "source": [
    "api_client.set.default_space(space_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "90b06755-6dc3-4052-bb29-5fd10694cd43"
   },
   "outputs": [],
   "source": [
    "config_yml =\\\n",
    "\"\"\"\n",
    "name: python311\n",
    "channels:\n",
    "  - empty\n",
    "dependencies:\n",
    "  - pip:\n",
    "    - langchain-ibm==0.3.5    \n",
    "    - langchain==0.3.22\n",
    "    - langchain-community==0.3.20\n",
    "    - langchain-core==0.3.50\n",
    "    - langgraph==0.2.70          \n",
    "    - pydantic==2.10.6\n",
    "    - PyHive==0.7.0\n",
    "    \n",
    "prefix: /opt/anaconda3/envs/python311\n",
    "\"\"\"\n",
    "\n",
    "with open(\"config_nl2sql.yaml\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(config_yml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register and Store Environment with Package Extension Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "60e3a28b-ad52-4a27-963b-790c7839e2f6"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "deployment_name = 'nl2sql-wxdata-deploy-' + datetime.now().strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aebf4a94-2c44-4d49-a20e-6b7fd14ddc23"
   },
   "outputs": [],
   "source": [
    "base_sw_spec_id = api_client.software_specifications.get_id_by_name(\"runtime-24.1-py3.11\")\n",
    "meta_prop_pkg_extn = {\n",
    "    api_client.package_extensions.ConfigurationMetaNames.NAME: deployment_name,\n",
    "    api_client.package_extensions.ConfigurationMetaNames.DESCRIPTION: \"Environment with langchain ai\",\n",
    "    api_client.package_extensions.ConfigurationMetaNames.TYPE: \"conda_yml\"\n",
    "}\n",
    "\n",
    "pkg_extn_details = api_client.package_extensions.store(meta_props=meta_prop_pkg_extn, file_path=\"config_nl2sql.yaml\")\n",
    "pkg_extn_id = api_client.package_extensions.get_id(pkg_extn_details)\n",
    "pkg_extn_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Store Software Specification with Package Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aa1ab21d-7224-4755-9ed8-50454bcfe0f5"
   },
   "outputs": [],
   "source": [
    "meta_prop_sw_spec = {\n",
    "    api_client.software_specifications.ConfigurationMetaNames.NAME: deployment_name,\n",
    "    api_client.software_specifications.ConfigurationMetaNames.DESCRIPTION: \"Software specification deployment\",\n",
    "    api_client.software_specifications.ConfigurationMetaNames.BASE_SOFTWARE_SPECIFICATION: {\"guid\": base_sw_spec_id}\n",
    "}\n",
    "\n",
    "sw_spec_details = api_client.software_specifications.store(meta_props=meta_prop_sw_spec)\n",
    "sw_spec_id = api_client.software_specifications.get_id(sw_spec_details)\n",
    "api_client.software_specifications.add_package_extension(sw_spec_id, pkg_extn_id)\n",
    "sw_spec_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store AI Service with Software Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ea44f080-ac5c-428b-b52d-2fe7405bb7c6"
   },
   "outputs": [],
   "source": [
    "\n",
    "meta_props = {\n",
    "    api_client.repository.AIServiceMetaNames.NAME: f\"AI service {deployment_name}\",\n",
    "    api_client.repository.AIServiceMetaNames.SOFTWARE_SPEC_ID: sw_spec_id\n",
    "}\n",
    "stored_ai_service_details = api_client.repository.store_ai_service(gen_ai_service, meta_props)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Stored AI Service ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2260f7f-bfec-4f36-a599-eddf063b874a"
   },
   "outputs": [],
   "source": [
    "ai_service_id = api_client.repository.get_ai_service_id(stored_ai_service_details)\n",
    "ai_service_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy AI Service with Crew AI Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a9581e77-195b-4c6e-81d6-30222293a39d"
   },
   "outputs": [],
   "source": [
    "meta_props = {\n",
    "    api_client.deployments.ConfigurationMetaNames.NAME: deployment_name,\n",
    "    api_client.deployments.ConfigurationMetaNames.ONLINE: {},\n",
    "}\n",
    "\n",
    "deployment_details = api_client.deployments.create(ai_service_id, meta_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "50a74d30-ccd8-470b-b72e-c2953719448f"
   },
   "outputs": [],
   "source": [
    "deployment_id = api_client.deployments.get_id(deployment_details)\n",
    "deployment_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f094c860-ab16-48a8-80b8-ce26c28dfb3e"
   },
   "outputs": [],
   "source": [
    "{\"messages\":\n",
    " [\n",
    "     { \"role\" : \"user\", \n",
    "      \"content\": \"Who are the clients (including names and IDs) who invested in IBM and is holding more than 10000. Give me just 5 such clients\" \n",
    "      }\n",
    "      ]\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c569ccf5-d40b-4468-9a2a-d7566d34edb3"
   },
   "outputs": [],
   "source": [
    "# history=\"Who are the clients (including names and IDs) who invested in IBM and is holding more than 10000. Give me just 5 such clients\"\n",
    "question= \"Who are the clients (including names and IDs) who invested in IBM and is holding more than 10000. Give me just 5 such clients\"        \n",
    "\n",
    "messages =[{ \"role\" : \"user\", \"content\": question }]\n",
    "\n",
    "    \n",
    "request_payload_json = {\"messages\":messages}\n",
    "\n",
    "deployments_results = api_client.deployments.run_ai_service(\n",
    "    deployment_id, request_payload_json #{\"history\": history}\n",
    ")\n",
    "deployments_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
