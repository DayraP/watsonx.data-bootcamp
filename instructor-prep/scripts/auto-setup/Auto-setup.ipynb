{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d65a5b46",
   "metadata": {},
   "source": [
    "# Autosetup\n",
    "> This file provisions Cloud Object Storage buckets, registers them in watsonx.data instance, associates catalogs, creates spark engine and milvus service and adds Postgres as a data source.  \n",
    "* You can start Auto-setup after :exclamation:**watsonx.data quickstart is finished** as before watsonx.data API that is used in this notebook is not available.\n",
    "* Additionally, make sure you have `.env_setup` created in the same folder and filled with relevant information.\n",
    "* COS instance and Postgres credentials should be added in `./credentials` folder in json format\n",
    "* Package requirements to run this JN are located in `requirements_autosetup.txt`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af8fc2a",
   "metadata": {},
   "source": [
    "## Expected output in watsonx.data infrastructure manager\n",
    "![](attachments/2025-05-23-19-34-59-pasted-vscode.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7175a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import xmltodict\n",
    "import io\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('./.env_setup')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1268853",
   "metadata": {},
   "source": [
    "## Initial configurations\n",
    "Names of engines and catalogs for watsonx.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff06acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_timestamp =  str(datetime.now().timestamp()).replace('.', '')\n",
    "\n",
    "env_json = dict()\n",
    "buckets_to_create = ['hive', 'milvus', 'input-data']\n",
    "\n",
    "presto_engine_name = f\"presto_{current_timestamp}\"\n",
    "spark_engine_name = f\"spark_{current_timestamp}\"\n",
    "milvus_servis_name = f\"milvus_{current_timestamp}\"\n",
    "\n",
    "hive_catalog = {\n",
    "        'catalog_name': 'hive_catalog',\n",
    "        'catalog_type': 'hive-hadoop2'\n",
    "      }\n",
    "iceberg_catalog = {\n",
    "        'catalog_name': 'iceberg_data',\n",
    "        'catalog_type': 'iceberg'\n",
    "      }\n",
    "postgres_catalog = {\n",
    "      'catalog_name': 'postgres_catalog',\n",
    "      'catalog_type': 'postgresql'\n",
    "}\n",
    "\n",
    "netezza_catalog = {\n",
    "      'catalog_name': 'nz_catalog',\n",
    "      'catalog_type': 'netezza'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52ebc67",
   "metadata": {},
   "source": [
    "## Credentials and configurations based on env and credentials folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591b0966",
   "metadata": {},
   "source": [
    "### Read in environmental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2a84b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# environmental variables for .data API support\n",
    "# urls\n",
    "identityURL = os.getenv(\"IDENTITY_URL\")\n",
    "#wxd_url = f'https://{os.getenv(\"WXD_REGION\")}.lakehouse.cloud.ibm.com/lakehouse/api/v2'\n",
    "wxd_url = 'https://console-ibm-cator.lakehouse.saas.ibm.com/lakehouse/api/v2'\n",
    "# buckets location the same as watsonx.data\n",
    "buckets_location = os.getenv(\"WXD_REGION\")\n",
    "bucket_endpoint =  f\"https://s3.{buckets_location}.cloud-object-storage.appdomain.cloud\"\n",
    "\n",
    "print(\"watsonx.data url\", wxd_url)\n",
    "print(f\"COS endpoint - the same as watsonx.data location {buckets_location}\", bucket_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f98e76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Netezza credentials\n",
    "nz_credentials = {\n",
    "    \"nz_database\": os.getenv(\"NZ_DATABASE\"),\n",
    "    \"nz_host\": os.getenv(\"NZ_HOST\"),\n",
    "    \"nz_port\": os.getenv(\"NZ_PORT\"),\n",
    "    \"nz_username\": os.getenv(\"NZ_USERNAME\"),\n",
    "    \"nz_password\": os.getenv(\"NZ_PASSWORD\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824e3296",
   "metadata": {},
   "source": [
    "### watsonx.data API urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5234303",
   "metadata": {},
   "outputs": [],
   "source": [
    "presto_url = f\"{wxd_url}/instance_details\"\n",
    "wxd_b_url = f\"{wxd_url}/bucket_registrations\"\n",
    "wxd_db_url = f\"{wxd_url}/database_registrations\"\n",
    "wxd_p_url = f\"{wxd_url}/presto_engines\"\n",
    "wxd_s_url = f\"{wxd_url}/spark_engines\"\n",
    "wxd_m_url = f\"{wxd_url}/milvus_services\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6043a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getenv('COS_CREDENTIALS_PATH')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf609df",
   "metadata": {},
   "source": [
    "### Parsing COS Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8a1e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.getenv('COS_CREDENTIALS_PATH')) as j_f:\n",
    "    cos_credentials_json = json.load(j_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4fbbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_json['COS_API_KEY'] = cos_credentials_json['apikey']\n",
    "env_json['COS_ACCESS_KEY'] = cos_credentials_json['cos_hmac_keys']['access_key_id']\n",
    "env_json['COS_SECRET_KEY'] = cos_credentials_json['cos_hmac_keys']['secret_access_key']\n",
    "env_json['COS_INSTANCE_CRN'] = cos_credentials_json['resource_instance_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300f9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wx.data credentials\n",
    "env_json['CLOUD_API_KEY'] = os.getenv(\"CLOUD_API_KEY\")\n",
    "env_json['WXD_INSTANCE_CRN'] = os.getenv(\"WXD_INSTANCE_CRN\")\n",
    "env_json['WXD_USER'] = \"ibmlhapikey\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffe01a1",
   "metadata": {},
   "source": [
    "### Generate token and use it for the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdfaa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_token():\n",
    "    \"\"\"To geneate user token for other requests\"\"\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        'grant_type': f'urn:ibm:params:oauth:grant-type:apikey',\n",
    "        'apikey': f\"{env_json['CLOUD_API_KEY']}\"\n",
    "    }\n",
    "\n",
    "    res = requests.post(f'{identityURL}', headers=headers, data=payload, verify=False)\n",
    "    if res.status_code in [200, 201, 202]:\n",
    "        print(\"Successfully generated token\")\n",
    "    else:\n",
    "        print(\"Code for token generation\", res.status_code)\n",
    "        print(\"Message\", res.text)\n",
    "    cur_string = res.json()\n",
    "    access_token = cur_string['access_token']\n",
    "\n",
    "    return access_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73adcfe1",
   "metadata": {},
   "source": [
    "### Functions to create sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54167c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cos_session(access_token):\n",
    "    s_cos = requests.Session()\n",
    "    s_cos.headers.clear()\n",
    "    headers_cos={\n",
    "        \"Authorization\":\"Bearer {}\".format(access_token),\n",
    "        \"ibm-service-instance-id\": env_json['COS_INSTANCE_CRN']\n",
    "    }\n",
    "\n",
    "    s_cos.headers.update(headers_cos) \n",
    "    print(\"COS API session created\")\n",
    "    return s_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9972df57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wxdata_session(access_token):\n",
    "    wxd_headers={\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Authorization\":\"Bearer {}\".format(access_token),\n",
    "    \"AuthInstanceID\": f\"{env_json['WXD_INSTANCE_CRN']}\"\n",
    "}\n",
    "    s_data = requests.Session()\n",
    "    s_data.headers.clear()\n",
    "    s_data.headers.update(wxd_headers)\n",
    "    print(\"wx data API session created\")\n",
    "    return s_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33339d9d",
   "metadata": {},
   "source": [
    "## COS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6ea465",
   "metadata": {},
   "source": [
    "### COS authentication -> session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3848ad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_token = generate_token()\n",
    "s_cos = create_cos_session(cur_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bc7894",
   "metadata": {},
   "source": [
    "### Create bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc28932",
   "metadata": {},
   "source": [
    "[bucket_endpoints](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-endpoints)  \n",
    "[COS API](https://cloud.ibm.com/apidocs/cos/cos-compatibility#createbucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6113c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_cos.get(bucket_endpoint).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a5dcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_buckets_names = []\n",
    "r = s_cos.get(bucket_endpoint)\n",
    "buckets_list = xmltodict.parse(r.text)['ListAllMyBucketsResult']['Buckets']\n",
    "buckets_dict=buckets_list['Bucket'] if 'Bucket' in buckets_list else []\n",
    "if type(buckets_dict) == dict:\n",
    "    if any(bucket_name in buckets_dict['Name'] for bucket_name in buckets_to_create):\n",
    "        ex_buckets_names.append(buckets_dict[\"Name\"])\n",
    "elif type(buckets_dict) == list:\n",
    "    for bucket in buckets_dict:\n",
    "        if any(bucket_name in bucket['Name'] for bucket_name in buckets_to_create):\n",
    "            ex_buckets_names.append(bucket[\"Name\"])\n",
    "\n",
    "# dictionary of created buckets\n",
    "created_buckets = dict.fromkeys(buckets_to_create)\n",
    "for bucket_name in ex_buckets_names:\n",
    "    cur_key = bucket_name.rsplit(\"-\", 1)[0]\n",
    "    created_buckets[cur_key] = bucket_name\n",
    "\n",
    "# to create buckets if some of them are None\n",
    "for bucket_name, existing_bucket in created_buckets.items():\n",
    "    if existing_bucket is None:\n",
    "        f_bucket_name = f\"{bucket_name}-{current_timestamp}{random.randint(100, 999)}\"\n",
    "        location=buckets_location\n",
    "        url_new_bucket = f\"{bucket_endpoint}/{f_bucket_name}\"\n",
    "        r = s_cos.put(url_new_bucket)\n",
    "        if r.status_code == 200:\n",
    "            created_buckets[bucket_name] = f_bucket_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9273fe92",
   "metadata": {},
   "source": [
    "### Delete bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0262a606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_cos.delete(url_new_bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ae8bfe",
   "metadata": {},
   "source": [
    "# watsonx.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debc48dd",
   "metadata": {},
   "source": [
    "### authenticate session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6e2d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_token = generate_token()\n",
    "s = create_wxdata_session(cur_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad34dcd",
   "metadata": {},
   "source": [
    "### Initial information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ac0032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep headers for the whole session\n",
    "wxd_info = s.get(presto_url)\n",
    "print(wxd_info.status_code)\n",
    "wxd_info.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55ff58f",
   "metadata": {},
   "source": [
    "### .data COS buckets registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6059496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = s.get(wxd_b_url)\n",
    "wxd_buckets_info = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476b75fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buckets to register\n",
    "buckets_registerations = list()\n",
    "for bucket_name in wxd_buckets_info['bucket_registrations']:\n",
    "    buckets_registerations.append(bucket_name['bucket_details']['bucket_name'])\n",
    "buckets_to_register = dict()\n",
    "for bucket_name, bucket_f_name in created_buckets.items():\n",
    "    if bucket_f_name in buckets_registerations or bucket_name == 'input-data':\n",
    "        continue\n",
    "    else:\n",
    "        buckets_to_register[bucket_name] = bucket_f_name\n",
    "print('Current buckets to register', buckets_to_register)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2616049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bucket_name in buckets_to_register:\n",
    "  if bucket_name == 'input-data':\n",
    "    continue\n",
    "  data = { \"bucket_details\": \n",
    "  { \"access_key\": env_json['COS_ACCESS_KEY'], \"bucket_name\": created_buckets[bucket_name], \"endpoint\": bucket_endpoint, \"secret_key\": env_json['COS_SECRET_KEY']}, \n",
    "  \"bucket_display_name\": bucket_name, \n",
    "  \"bucket_type\": \"ibm_cos\", \n",
    "  \"description\": f\"COS bucket for {bucket_name} data\",\n",
    "  \"managed_by\": \"customer\", \n",
    "  \"region\": buckets_location\n",
    "    }\n",
    "  # for iceberg add iceberg catalog\n",
    "  if bucket_name == 'wxd':\n",
    "    data['associated_catalog'] = iceberg_catalog\n",
    "  # for hive add hive catalog\n",
    "  if bucket_name == 'hive':\n",
    "    data['associated_catalog'] = hive_catalog\n",
    "  r = s.post(wxd_b_url, data=json.dumps(data))\n",
    "  print(\"Register\", bucket_name, r.status_code, r.text)\n",
    "  # to activate if created successfully\n",
    "  if r.status_code in [200, 201] and bucket_name in ['wxd', 'hive']:\n",
    "    wxd_ba_url = f\"{wxd_b_url}/{created_buckets[bucket_name]}/activate\"\n",
    "    r = s.post(wxd_ba_url, data=\"\")\n",
    "    print(\"Activate\", r.status_code, r.text)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9108234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find bucket registered for iceberg catalog (default bucket)\n",
    "for bucket_info in wxd_buckets_info['bucket_registrations']:\n",
    "    if len(bucket_info['associated_catalogs'])==0:\n",
    "        continue\n",
    "    for associated_catalog in bucket_info['associated_catalogs']:\n",
    "        if 'iceberg' in associated_catalog['catalog_name']:\n",
    "            # correct catalog name if incorrect\n",
    "            iceberg_catalog['catalog_name'] = associated_catalog['catalog_name']\n",
    "            if created_buckets.get('wxd') is None:\n",
    "                created_buckets['wxd'] = bucket_info['bucket_details']['bucket_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7606cf39",
   "metadata": {},
   "source": [
    "### postgres as data source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3367fb",
   "metadata": {},
   "source": [
    "#### Postgres credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31240a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.getenv('POSTGRES_CREDENTIALS_PATH')) as j_f:\n",
    "    postgres_cred_json = json.load(j_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b446ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"database_display_name\": \"Postgres\",\n",
    "    \"database_type\": \"postgresql\",\n",
    "    \"associated_catalog\": {\n",
    "        \"catalog_name\": postgres_catalog[\"catalog_name\"],\n",
    "        \"catalog_type\": postgres_catalog[\"catalog_type\"]\n",
    "    },\n",
    "    \"database_details\": {\n",
    "        \"hostname\": postgres_cred_json[\"connection\"][\"cli\"][\"arguments\"][0][0].split(' ')[0].split('=')[-1],\n",
    "        \"port\": int(postgres_cred_json[\"connection\"][\"cli\"][\"arguments\"][0][0].split(' ')[1].split('=')[-1]),\n",
    "        \"database_name\": postgres_cred_json[\"connection\"][\"cli\"][\"arguments\"][0][0].split(' ')[2].split('=')[-1],\n",
    "        \"password\": postgres_cred_json[\"connection\"][\"postgres\"][\"authentication\"][\"password\"],\n",
    "        \"username\": postgres_cred_json[\"connection\"][\"postgres\"][\"authentication\"][\"username\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcda2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if added, if not add\n",
    "postgres_registration = False\n",
    "database_registations = s.get(wxd_db_url).json()['database_registrations']\n",
    "if database_registations is not None:\n",
    "    for database_registration in database_registations:\n",
    "        if database_registration['database_type'] == 'postgresql':\n",
    "            postgres_registration = True\n",
    "            print(\"Postgres registration already exists, won't be adding a new one\")\n",
    "if not postgres_registration:\n",
    "    r = s.post(wxd_db_url, data=json.dumps(data))\n",
    "    print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7fb707",
   "metadata": {},
   "source": [
    "### Netezza as data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4741239b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nz_data = {\n",
    "    \"database_display_name\": \"INVESTMENTS_NZ\",\n",
    "    \"database_type\": \"netezza\",\n",
    "    \"associated_catalog\": {\n",
    "        \"catalog_name\": netezza_catalog[\"catalog_name\"],\n",
    "        \"catalog_type\": netezza_catalog[\"catalog_type\"]\n",
    "    },\n",
    "    \"database_details\": {\n",
    "        \"hostname\": nz_credentials[\"nz_host\"],\n",
    "        \"port\": int(nz_credentials[\"nz_port\"]),\n",
    "        \"database_name\": nz_credentials[\"nz_database\"],\n",
    "        \"password\": nz_credentials[\"nz_password\"],\n",
    "        \"username\": nz_credentials[\"nz_username\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c99bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if added, if not add\n",
    "netezza_registration = False\n",
    "database_registations = s.get(wxd_db_url).json()['database_registrations']\n",
    "if database_registations is not None:\n",
    "    for database_registration in database_registations:\n",
    "        if database_registration['database_type'] == 'netezza':\n",
    "            netezza_registration = True\n",
    "            print(\"Netezza registration already exists, won't be adding a new one\")\n",
    "if not netezza_registration:\n",
    "    r = s.post(wxd_db_url, data=json.dumps(nz_data))\n",
    "    print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f779128",
   "metadata": {},
   "source": [
    "### .data engines and service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1682e2b0",
   "metadata": {},
   "source": [
    "#### presto engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415019b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"description\": \"\",\n",
    "    \"engine_details\": {\n",
    "        \"coordinator\": {\n",
    "            \"node_type\": \"starter\",\n",
    "            \"quantity\": 1\n",
    "        },\n",
    "        \"size_config\": \"custom\",\n",
    "        \"worker\": {\n",
    "            \"node_type\": \"starter\",\n",
    "            \"quantity\": 1\n",
    "        }\n",
    "    },\n",
    "    \"engine_display_name\": f\"{presto_engine_name}2\",\n",
    "    \"origin\": \"native\",\n",
    "    \"associated_catalogs\": [iceberg_catalog['catalog_name'], hive_catalog['catalog_name']],\n",
    "    \"version\": \"v0.286\",\n",
    "    \"tags\": [],\n",
    "    \"region\": \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7ccfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if presto engine exists, if not create one\n",
    "presto_engines = s.get(wxd_p_url).json()\n",
    "# provision engine if not\n",
    "if presto_engines['presto_engines'] is None:\n",
    "    r = s.post(wxd_p_url, data=json.dumps(data))\n",
    "    print(r.status_code)\n",
    "    print(r.text)\n",
    "    # wait till provisionning is finished\n",
    "    if r.status_code in [200, 201, 202]:\n",
    "        start_time=time.time()\n",
    "        engine_wait = True\n",
    "        while time.time() - start_time < 200 and engine_wait:\n",
    "            try:\n",
    "                r = s.get(wxd_p_url)\n",
    "                if r.json()['presto_engines'] is None:\n",
    "                    print(\"Provisioning not started yes. Waiting...\")\n",
    "                    time.sleep(10)\n",
    "                    continue\n",
    "                if r.json()['presto_engines'][0]['status'].upper() in ['PENDING', 'PROVISIONING']:\n",
    "                    print(\"Provisioning presto engine. Waiting...\")\n",
    "                    time.sleep(30)\n",
    "                    continue                \n",
    "                if r.json()['presto_engines'][0]['status'].upper() == 'RUNNING':\n",
    "                    print(\"Engine has provisioned\")\n",
    "                    engine_wait = False\n",
    "                    continue\n",
    "                print(\"Timeout reached.  Engine not provisioned\")\n",
    "            except requests.RequestException as e:\n",
    "                print(f\"Request failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da17614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename presto engine\n",
    "presto_engines = s.get(wxd_p_url).json()['presto_engines']\n",
    "presto_engine_id = presto_engines[0]['engine_id']\n",
    "if presto_engines[0]['engine_display_name'] != presto_engine_name:\n",
    "    data = {\n",
    "        \"engine_display_name\": presto_engine_name\n",
    "    }\n",
    "    r = s.patch(f\"{wxd_p_url}/{presto_engine_id}\", data=json.dumps(data))\n",
    "    print(r.status_code, r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d48725e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# associate catalogs if not yes\n",
    "p_catalogs = presto_engines[0]['associated_catalogs'].copy()\n",
    "catalogs_associate = []\n",
    "if not any('hive' in cat for cat in p_catalogs):\n",
    "    catalogs_associate.append(hive_catalog['catalog_name'])\n",
    "if not any('iceberg' in cat for cat in p_catalogs):\n",
    "    catalogs_associate.append(iceberg_catalog['catalog_name'])\n",
    "if not any('postgre' in cat for cat in p_catalogs):\n",
    "    catalogs_associate.append(postgres_catalog['catalog_name'])\n",
    "if not any('netezza' in cat for cat in p_catalogs):\n",
    "    catalogs_associate.append(netezza_catalog['catalog_name'])\n",
    "\n",
    "if catalogs_associate:\n",
    "    data = {\n",
    "        \"catalog_names\": ','.join(catalogs_associate)\n",
    "    }\n",
    "    r = s.post(f\"{wxd_p_url}/{presto_engine_id}/catalogs\", data=json.dumps(data))\n",
    "    print(r.status_code, r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4082a836",
   "metadata": {},
   "source": [
    "#### spark engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f229bded",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"description\": \"Spark engine\",\n",
    "    \"type\": \"spark\",\n",
    "    \"engine_details\": {\n",
    "        \"default_version\": \"3.5\",\n",
    "        \"scale_config\": {\n",
    "            \"node_type\": \"small\",\n",
    "            \"number_of_nodes\": 3\n",
    "        },\n",
    "        \"engine_home_bucket_name\": created_buckets['wxd']\n",
    "    },\n",
    "    \"engine_display_name\": spark_engine_name,\n",
    "    \"origin\": \"native\",\n",
    "    \"associated_catalogs\": [iceberg_catalog['catalog_name'], hive_catalog['catalog_name']]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b3f081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if spark engine exists, if not create one\n",
    "spark_engines = s.get(wxd_s_url).json()\n",
    "# provision engine if not\n",
    "if spark_engines['spark_engines'] is None:\n",
    "    r = s.post(wxd_s_url, data=json.dumps(data))\n",
    "    print(r.status_code)\n",
    "    print(r.text)\n",
    "    # wait till provisionning is finished\n",
    "    if r.status_code in [200, 201, 202]:\n",
    "        start_time=time.time()\n",
    "        engine_wait = True\n",
    "        while time.time() - start_time < 200 and engine_wait:\n",
    "            try:\n",
    "                r = s.get(wxd_s_url)\n",
    "                if r.json()['spark_engines'] is None:\n",
    "                    print(\"Provisioning not started yes. Waiting...\")\n",
    "                    time.sleep(10)\n",
    "                    continue\n",
    "                if r.json()['spark_engines'][0]['status'].upper() in ['PENDING', 'PROVISIONING']:\n",
    "                    print(\"Provisioning spark engine. Waiting...\")\n",
    "                    time.sleep(30)\n",
    "                    continue                \n",
    "                if r.json()['spark_engines'][0]['status'].upper() == 'RUNNING':\n",
    "                    print(\"Engine has provisioned\")\n",
    "                    engine_wait = False\n",
    "                    continue\n",
    "                print('Request has timed out')\n",
    "            except requests.RequestException as e:\n",
    "                print(f\"Request failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000c9879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that iceberg and hive catalogs are associated\n",
    "# associate catalogs if not yes\n",
    "spark_engines = s.get(wxd_s_url).json()\n",
    "spark_engine_id = spark_engines['spark_engines'][0]['engine_id']\n",
    "s_catalogs = spark_engines['spark_engines'][0]['associated_catalogs'].copy()\n",
    "catalogs_associate = []\n",
    "if not any('hive' in cat for cat in s_catalogs):\n",
    "    catalogs_associate.append(hive_catalog['catalog_name'])\n",
    "if not any('iceberg' in cat for cat in s_catalogs):\n",
    "    catalogs_associate.append(iceberg_catalog['catalog_name'])\n",
    "\n",
    "if catalogs_associate:\n",
    "    data = {\n",
    "        \"catalog_names\": ','.join(catalogs_associate)\n",
    "    }\n",
    "    r = s.post(f\"{wxd_s_url}/{spark_engine_id}/catalogs\", data=json.dumps(data))\n",
    "    print(r.status_code, r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84de081",
   "metadata": {},
   "source": [
    "#### milvus service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1ba814",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"origin\": \"native\",\n",
    "    \"bucket_name\": created_buckets[\"milvus\"],\n",
    "    \"bucket_type\": \"ibm_cos\",\n",
    "    \"service_display_name\": milvus_servis_name,\n",
    "    \"root_path\": f\"/{milvus_servis_name}_metadata\",\n",
    "    \"tshirt_size\": \"starter\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd52bf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.get(wxd_m_url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010004ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = s.post(wxd_m_url, data=json.dumps(data))\n",
    "print(r.status_code, r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c85dba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if exists, if not create (wait till it's provisioned)\n",
    "milvus_services = s.get(wxd_m_url).json()\n",
    "# provision engine if not\n",
    "if milvus_services['milvus_services'] == [] or milvus_services['milvus_services'] is None:\n",
    "    r = s.post(wxd_m_url, data=json.dumps(data))\n",
    "    print(r.status_code)\n",
    "    print(r.text)\n",
    "    # wait till provisionning is finished\n",
    "    if r.status_code in [200, 201, 202]:\n",
    "        start_time=time.time()\n",
    "        engine_wait = True\n",
    "        while time.time() - start_time < 1200 and engine_wait:\n",
    "            try:\n",
    "                r = s.get(wxd_m_url)\n",
    "                if r.json()['milvus_services'] == [] or r.json()['milvus_services'] is None:\n",
    "                    print(\"Provisioning not started yes. Waiting...\")\n",
    "                    time.sleep(10)\n",
    "                    continue\n",
    "                if r.json()['milvus_services'][0]['status'].upper() in ['PENDING', 'PROVISIONING']:\n",
    "                    print(\"Provisioning spark engine. Waiting...\")\n",
    "                    time.sleep(30)\n",
    "                    continue                \n",
    "                if r.json()['milvus_services'][0]['status'].upper() == 'RUNNING':\n",
    "                    print(\"Engine has provisioned\")\n",
    "                    engine_wait = False\n",
    "                    continue\n",
    "                print('Request has timed out')\n",
    "            except requests.RequestException as e:\n",
    "                print(f\"Request failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54744bf1",
   "metadata": {},
   "source": [
    "## Create env file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eced6d",
   "metadata": {},
   "source": [
    "### Add initial information from env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb8051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_json['IDENTITY_URL'] = os.getenv(\"IDENTITY_URL\")\n",
    "env_json['WXD_REGION'] = os.getenv(\"WXD_REGION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d048b37f",
   "metadata": {},
   "source": [
    "### Update watsonx.data session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588980a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_token = generate_token()\n",
    "s = create_wxdata_session(cur_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f08d1d",
   "metadata": {},
   "source": [
    "### Add COS buckets information and catalogs associated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de94c86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_buckets = s.get(wxd_b_url)\n",
    "buckets_info = r_buckets.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90df44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoints = {}\n",
    "for bucket_info in buckets_info['bucket_registrations']:\n",
    "    if 'milvus' in bucket_info['bucket_details']['bucket_name']:\n",
    "        env_json['MILVUS_BUCKET'] =  bucket_info['bucket_details']['bucket_name']\n",
    "        endpoints['milvus'] = bucket_info['bucket_details']['endpoint']\n",
    "        continue\n",
    "    if 'hive' in bucket_info['associated_catalogs'][0]['catalog_name']:\n",
    "        env_json['HIVE_CATALOG'] = bucket_info['associated_catalogs'][0]['catalog_name']\n",
    "        env_json['HIVE_BUCKET'] =  bucket_info['bucket_details']['bucket_name']\n",
    "        endpoints['hive'] = bucket_info['bucket_details']['endpoint']\n",
    "        continue\n",
    "    if 'iceberg' in bucket_info['associated_catalogs'][0]['catalog_name']:\n",
    "        env_json['ICEBERG_CATALOG'] = bucket_info['associated_catalogs'][0]['catalog_name']\n",
    "        env_json['WXD_BUCKET'] =  bucket_info['bucket_details']['bucket_name']\n",
    "        endpoints['iceberg'] = bucket_info['bucket_details']['endpoint']\n",
    "        continue\n",
    "env_json['INPUT_BUCKET'] = created_buckets['input-data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4120d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_values = [url_v.split(\"://\")[1].split(\".\")[-4] for url_v in endpoints.values()]\n",
    "all_same = all(v == end_values[0] for v in end_values)\n",
    "\n",
    "print('Are all of the bucket endpoints the same?', all_same)\n",
    "\n",
    "env_json['COS_BUCKETS_LOCATION'] = end_values[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804cf4f2",
   "metadata": {},
   "source": [
    "If False check which endpoint is not the same (if it's the region or direct / public endpoint only)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397d9c26",
   "metadata": {},
   "source": [
    "### Update env file with engines and milvus service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aa30a7",
   "metadata": {},
   "source": [
    ":exclamation:make sure that all engines and milvus are provisioned (in the UI)!!!  \n",
    "**Milvus** might take longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659c5efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update info first\n",
    "wxd_info = s.get(presto_url)\n",
    "if wxd_info.status_code == 200:\n",
    "    wxd_engines = wxd_info.json()['engines_services']\n",
    "    for c_engine in wxd_engines:\n",
    "        if c_engine['type'] == 'presto':\n",
    "            env_json['PRESTO_HOST'] = c_engine['details'][0]['internal']['hostname']\n",
    "            env_json['PRESTO_PORT'] = c_engine['details'][0]['internal']['port']\n",
    "        if c_engine['type'] == 'spark_native':\n",
    "            env_json['SPARK_ENGINE_ID'] = c_engine['details'][0]['id']\n",
    "        if c_engine['type'] == 'milvus':\n",
    "            assert 'hostname' in c_engine['details'][0]['grpc_api_endpoint'], 'MILVUS is still being setup'\n",
    "            env_json['MILVUS_HOST'] = c_engine['details'][0]['grpc_api_endpoint']['hostname']\n",
    "            env_json['MILVUS_PORT'] = c_engine['details'][0]['grpc_api_endpoint']['port']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824729c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to .env format\n",
    "with open('.env_output', 'w') as env_file:\n",
    "    for key, value in env_json.items():\n",
    "        # Convert value to string and quote it\n",
    "        quoted_value = f'\"{str(value)}\"'\n",
    "        env_file.write(f\"{key}={quoted_value}\\n\")\n",
    "print(\"Checkout .env_output file in the current directory\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_prep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
